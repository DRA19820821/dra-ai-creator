"""
N√≥s de Processamento de Feedback do Usu√°rio
"""
import json
from typing import Dict, Any
from langchain_core.messages import HumanMessage, AIMessage

from core.state import AgentState
from core.schemas import PlanOutput
from utils.llm_factory import create_llm
from utils.logger import log_node_start, log_node_complete, log_node_error, log_llm_call
from config.llm_config import estimate_cost


def wait_user_approval(state: AgentState) -> Dict[str, Any]:
    """
    N√≥ que aguarda aprova√ß√£o do usu√°rio (checkpoint)
    
    Este √© um n√≥ de controle que n√£o executa nada.
    O fluxo √© pausado aqui at√© que o usu√°rio:
    - Aprove o plano (user_approved=True)
    - Ou solicite ajustes (user_feedback com texto)
    
    Args:
        state: Estado atual do grafo
        
    Returns:
        Atualiza√ß√µes para o estado
    """
    log_node_start("wait_user_approval")
    
    # Esse n√≥ √© apenas um marcador
    # A l√≥gica de decis√£o est√° no roteamento do grafo
    
    log_node_complete("wait_user_approval")
    
    return {
        "current_step": "waiting_approval"
    }


def process_feedback(state: AgentState) -> Dict[str, Any]:
    """
    Processa o feedback do usu√°rio e ajusta o plano
    
    Args:
        state: Estado atual do grafo
        
    Returns:
        Atualiza√ß√µes para o estado
    """
    log_node_start("process_feedback", {"feedback": state.get("user_feedback", "")[:100]})
    
    try:
        # Verificar se h√° feedback
        user_feedback = state.get("user_feedback", "")
        if not user_feedback:
            # Se n√£o h√° feedback mas chegou aqui, √© porque foi rejeitado pela revis√£o
            # Usar issues da revis√£o como feedback
            plan_review = state.get("plan_review", {})
            issues = plan_review.get("issues_found", [])
            suggestions = plan_review.get("suggestions", [])
            
            feedback_parts = ["Ajustes necess√°rios baseados na revis√£o:"]
            feedback_parts.extend([f"- {issue}" for issue in issues[:5]])
            feedback_parts.extend([f"Sugest√£o: {sug}" for sug in suggestions[:3]])
            
            user_feedback = "\n".join(feedback_parts)
        
        # Obter modelo configurado
        model_name = state["selected_models"].get("planner", "claude-sonnet-4-5-20250929")
        llm = create_llm(model_name, temperature=0.5, max_tokens=4000)
        
        # Usar with_structured_output
        structured_llm = llm.with_structured_output(PlanOutput)
        
        # Criar prompt para ajustar o plano
        adjust_prompt = f"""Voc√™ √© um especialista em planejamento t√©cnico.

Voc√™ criou um plano, mas recebeu feedback solicitando ajustes.

## PLANO ORIGINAL:
{json.dumps(state["plan"], indent=2)}

## FEEDBACK RECEBIDO:
{user_feedback}

## SUA TAREFA:
Ajustar o plano incorporando o feedback. Mantenha o que est√° bom e modifique apenas o necess√°rio.

Retorne o plano ajustado no mesmo formato, com todos os campos preenchidos."""
        
        # Chamar LLM com structured output
        log_llm_call("feedback_processor", model_name)
        result: PlanOutput = structured_llm.invoke([HumanMessage(content=adjust_prompt)])
        
        # Converter para dict
        adjusted_plan = result.model_dump()
        
        # Converter steps e risks para dict se necess√°rio
        if hasattr(result, 'steps') and result.steps:
            adjusted_plan['steps'] = [step.model_dump() if hasattr(step, 'model_dump') else step for step in result.steps]
        
        if hasattr(result, 'risks') and result.risks:
            adjusted_plan['risks'] = [risk.model_dump() if hasattr(risk, 'model_dump') else risk for risk in result.risks]
        
        # Estimar custo
        tokens_in = len(adjust_prompt.split()) * 1.3
        tokens_out = 800
        cost = estimate_cost(model_name, int(tokens_in), int(tokens_out))
        
        # Incrementar contador de itera√ß√µes
        new_iteration = state.get("feedback_iteration", 0) + 1
        
        # Adicionar ao hist√≥rico
        new_messages = [
            HumanMessage(content=f"Feedback do usu√°rio: {user_feedback[:200]}..."),
            AIMessage(content=f"üîÑ Plano ajustado (itera√ß√£o {new_iteration})")
        ]
        
        log_node_complete("process_feedback", {"iteration": new_iteration})
        
        # Limitar itera√ß√µes para evitar loop infinito
        MAX_ITERATIONS = 3
        if new_iteration >= MAX_ITERATIONS:
            return {
                "plan": adjusted_plan,
                "feedback_iteration": new_iteration,
                "warnings": state["warnings"] + [
                    f"Atingido limite de {MAX_ITERATIONS} itera√ß√µes de feedback"
                ],
                "current_step": "build_solution",  # For√ßa prosseguir
                "messages": new_messages,
                "total_tokens_used": state["total_tokens_used"] + int(tokens_in + tokens_out),
                "total_cost": state["total_cost"] + cost,
            }
        
        return {
            "plan": adjusted_plan,
            "feedback_iteration": new_iteration,
            "user_feedback": None,  # Limpar feedback
            "user_approved": False,  # Resetar aprova√ß√£o
            "current_step": "review_plan",  # Volta para revis√£o
            "messages": new_messages,
            "total_tokens_used": state["total_tokens_used"] + int(tokens_in + tokens_out),
            "total_cost": state["total_cost"] + cost,
        }
        
    except Exception as e:
        log_node_error("process_feedback", e)
        return {
            "errors": state["errors"] + [f"Erro ao processar feedback: {str(e)}"],
            "current_step": "error"
        }


def route_after_plan_review(state: AgentState) -> str:
    """
    Fun√ß√£o de roteamento ap√≥s revis√£o do plano
    
    Args:
        state: Estado atual
        
    Returns:
        Nome do pr√≥ximo n√≥
    """
    plan_review = state.get("plan_review", {})
    is_approved = plan_review.get("is_approved", False)
    
    if is_approved:
        return "wait_user_approval"
    else:
        return "process_feedback"


def route_after_user_approval(state: AgentState) -> str:
    """
    Fun√ß√£o de roteamento ap√≥s checkpoint de aprova√ß√£o do usu√°rio
    
    Args:
        state: Estado atual
        
    Returns:
        Nome do pr√≥ximo n√≥
    """
    if state.get("user_approved", False):
        return "build_solution"
    else:
        # Usu√°rio deu feedback
        return "process_feedback"