"""
N√≥s de Processamento de Feedback do Usu√°rio
VERS√ÉO CORRIGIDA - Tratamento robusto de None
"""
import json
from typing import Dict, Any
from langchain_core.messages import HumanMessage, AIMessage

from core.state import AgentState
from core.schemas import PlanOutput
from utils.llm_factory import create_llm
from utils.logger import log_node_start, log_node_complete, log_node_error, log_llm_call
from config.llm_config import estimate_cost


def wait_user_approval(state: AgentState) -> Dict[str, Any]:
    """
    N√≥ que aguarda aprova√ß√£o do usu√°rio (checkpoint)
    
    Este √© um n√≥ de controle que n√£o executa nada.
    O fluxo √© pausado aqui at√© que o usu√°rio:
    - Aprove o plano (user_approved=True)
    - Ou solicite ajustes (user_feedback com texto)
    
    Args:
        state: Estado atual do grafo
        
    Returns:
        Atualiza√ß√µes para o estado
    """
    log_node_start("wait_user_approval")
    
    # Esse n√≥ √© apenas um marcador
    # A l√≥gica de decis√£o est√° no roteamento do grafo
    
    log_node_complete("wait_user_approval")
    
    return {
        "current_step": "waiting_approval"
    }


def process_feedback(state: AgentState) -> Dict[str, Any]:
    """
    Processa o feedback do usu√°rio e ajusta o plano
    VERS√ÉO ROBUSTA - Tratamento completo de erros
    
    Args:
        state: Estado atual do grafo
        
    Returns:
        Atualiza√ß√µes para o estado
    """
    log_node_start("process_feedback", {"feedback": state.get("user_feedback", "")[:100]})
    
    try:
        # ‚úÖ VERIFICAR SE STATE E PLAN EXISTEM
        if not state:
            raise ValueError("State is None")
        
        if not state.get("plan"):
            raise ValueError("Plan not found in state")
        
        # Verificar se h√° feedback
        user_feedback = state.get("user_feedback", "")
        if not user_feedback:
            # Se n√£o h√° feedback mas chegou aqui, √© porque foi rejeitado pela revis√£o
            # Usar issues da revis√£o como feedback
            plan_review = state.get("plan_review", {})
            if not plan_review:
                # ‚úÖ FALLBACK: Se nem review existe, usar feedback gen√©rico
                user_feedback = "Por favor, revise e melhore o plano considerando os requisitos."
            else:
                issues = plan_review.get("issues_found", [])
                suggestions = plan_review.get("suggestions", [])
                
                feedback_parts = ["Ajustes necess√°rios baseados na revis√£o:"]
                feedback_parts.extend([f"- {issue}" for issue in issues[:5]])
                feedback_parts.extend([f"Sugest√£o: {sug}" for sug in suggestions[:3]])
                
                user_feedback = "\n".join(feedback_parts)
        
        # Obter modelo configurado
        model_name = state["selected_models"].get("planner", "gemini-2.5-pro")
        llm = create_llm(model_name, temperature=0.5, max_tokens=4000)
        
        # Usar with_structured_output
        structured_llm = llm.with_structured_output(PlanOutput)
        
        # Criar prompt para ajustar o plano
        adjust_prompt = f"""Voc√™ √© um especialista em planejamento t√©cnico.

Voc√™ criou um plano, mas recebeu feedback solicitando ajustes.

## PLANO ORIGINAL:
{json.dumps(state["plan"], indent=2)}

## FEEDBACK RECEBIDO:
{user_feedback}

## SUA TAREFA:
Ajustar o plano incorporando o feedback. Mantenha o que est√° bom e modifique apenas o necess√°rio.

Retorne o plano ajustado no mesmo formato, com todos os campos preenchidos."""
        
        # Chamar LLM com structured output
        log_llm_call("feedback_processor", model_name)
        
        # ‚úÖ MULTI-TENTATIVA
        max_retries = 2
        adjusted_plan = None
        
        for attempt in range(max_retries):
            try:
                result = structured_llm.invoke([HumanMessage(content=adjust_prompt)])
                
                # ‚úÖ VERIFICAR SE RETORNOU NONE
                if result is None:
                    print(f"‚ö†Ô∏è Tentativa {attempt + 1}: Structured output retornou None")
                    if attempt < max_retries - 1:
                        continue
                    # ‚úÖ FALLBACK: Manter plano original com aviso
                    adjusted_plan = state["plan"].copy()
                    break
                
                # Converter para dict
                adjusted_plan = result.model_dump()
                
                # ‚úÖ Converter steps e risks se necess√°rio
                if hasattr(result, 'steps') and result.steps:
                    if hasattr(result.steps[0], 'model_dump'):
                        adjusted_plan['steps'] = [step.model_dump() for step in result.steps]
                
                if hasattr(result, 'risks') and result.risks:
                    if hasattr(result.risks[0], 'model_dump'):
                        adjusted_plan['risks'] = [risk.model_dump() for risk in result.risks]
                
                print(f"‚úÖ Plano ajustado com sucesso")
                break
                
            except Exception as e:
                print(f"‚ö†Ô∏è Erro na tentativa {attempt + 1}: {e}")
                if attempt < max_retries - 1:
                    continue
                # ‚úÖ FALLBACK FINAL: Manter plano original
                adjusted_plan = state["plan"].copy()
                break
        
        # ‚úÖ GARANTIR QUE adjusted_plan N√ÉO √â NONE
        if adjusted_plan is None:
            print("‚ö†Ô∏è Usando plano original como fallback")
            adjusted_plan = state["plan"].copy()
        
        # Estimar custo
        tokens_in = len(adjust_prompt.split()) * 1.3
        tokens_out = 800
        cost = estimate_cost(model_name, int(tokens_in), int(tokens_out))
        
        # Incrementar contador de itera√ß√µes
        new_iteration = state.get("feedback_iteration", 0) + 1
        
        # Adicionar ao hist√≥rico
        new_messages = [
            HumanMessage(content=f"Feedback do usu√°rio: {user_feedback[:200]}..."),
            AIMessage(content=f"üîÑ Plano ajustado (itera√ß√£o {new_iteration})")
        ]
        
        log_node_complete("process_feedback", {"iteration": new_iteration})
        
        # Limitar itera√ß√µes para evitar loop infinito
        MAX_ITERATIONS = 3
        if new_iteration >= MAX_ITERATIONS:
            return {
                "plan": adjusted_plan,
                "feedback_iteration": new_iteration,
                "warnings": state.get("warnings", []) + [
                    f"Atingido limite de {MAX_ITERATIONS} itera√ß√µes de feedback"
                ],
                "current_step": "build_solution",  # For√ßa prosseguir
                "messages": new_messages,
                "total_tokens_used": state.get("total_tokens_used", 0) + int(tokens_in + tokens_out),
                "total_cost": state.get("total_cost", 0.0) + cost,
            }
        
        return {
            "plan": adjusted_plan,
            "feedback_iteration": new_iteration,
            "user_feedback": None,  # Limpar feedback
            "user_approved": False,  # Resetar aprova√ß√£o
            "current_step": "review_plan",  # Volta para revis√£o
            "messages": new_messages,
            "total_tokens_used": state.get("total_tokens_used", 0) + int(tokens_in + tokens_out),
            "total_cost": state.get("total_cost", 0.0) + cost,
        }
        
    except Exception as e:
        log_node_error("process_feedback", e)
        
        import traceback
        print("\n‚ùå ERRO COMPLETO:")
        print(traceback.format_exc())
        
        # ‚úÖ FALLBACK: Retornar erro mas n√£o travar
        return {
            "errors": state.get("errors", []) + [f"Erro ao processar feedback: {str(e)}"],
            "warnings": state.get("warnings", []) + ["Feedback n√£o processado - prosseguindo"],
            "current_step": "build_solution",  # Prosseguir mesmo com erro
        }


def route_after_plan_review(state: AgentState) -> str:
    """
    Fun√ß√£o de roteamento ap√≥s revis√£o do plano
    VERS√ÉO ROBUSTA
    
    Args:
        state: Estado atual
        
    Returns:
        Nome do pr√≥ximo n√≥
    """
    # ‚úÖ VERIFICAR SE STATE EXISTE
    if not state:
        return "process_feedback"
    
    plan_review = state.get("plan_review", {})
    
    # ‚úÖ VERIFICAR SE REVIEW EXISTE
    if not plan_review:
        # Se n√£o tem review, assumir aprovado
        return "wait_user_approval"
    
    is_approved = plan_review.get("is_approved", False)
    
    if is_approved:
        return "wait_user_approval"
    else:
        return "process_feedback"


def route_after_user_approval(state: AgentState) -> str:
    """
    Fun√ß√£o de roteamento ap√≥s checkpoint de aprova√ß√£o do usu√°rio
    VERS√ÉO ROBUSTA
    
    Args:
        state: Estado atual
        
    Returns:
        Nome do pr√≥ximo n√≥ ou "wait" para pausar
    """
    # ‚úÖ VERIFICAR SE STATE EXISTE
    if not state:
        return "wait"
    
    # Se aprovado explicitamente, prosseguir
    if state.get("user_approved", False):
        return "build_solution"
    
    # Se h√° feedback, processar
    if state.get("user_feedback"):
        return "process_feedback"
    
    # Se nenhum dos dois, terminar e aguardar decis√£o do usu√°rio
    return "wait"