"""
NÃ³ Revisor GenÃ©rico - UtilitÃ¡rio para revisÃµes

Este mÃ³dulo contÃ©m funÃ§Ãµes auxiliares para revisÃ£o que podem ser
reutilizadas em diferentes contextos.
"""
import json
from typing import Dict, Any, Optional
from langchain_core.messages import HumanMessage
from langchain_core.language_models.chat_models import BaseChatModel

from utils.logger import log_validation
from config.llm_config import estimate_cost


def generic_review(
    content_to_review: Dict[str, Any],
    review_prompt: str,
    llm: BaseChatModel,
    model_name: str,
    node_name: str,
    min_confidence: float = 0.7
) -> tuple[Dict[str, Any], int, float]:
    """
    FunÃ§Ã£o genÃ©rica para realizar revisÃµes usando LLM
    
    Args:
        content_to_review: ConteÃºdo a ser revisado
        review_prompt: Prompt formatado para a revisÃ£o
        llm: InstÃ¢ncia do LLM
        model_name: Nome do modelo sendo usado
        node_name: Nome do nÃ³ (para logging)
        min_confidence: ConfianÃ§a mÃ­nima para aprovaÃ§Ã£o
        
    Returns:
        Tupla (review_result, tokens_used, cost)
    """
    # Chamar LLM
    response = llm.invoke([HumanMessage(content=review_prompt)])
    response_text = response.content
    
    # Parse JSON
    if "```json" in response_text:
        response_text = response_text.split("```json")[1].split("```")[0]
    elif "```" in response_text:
        response_text = response_text.split("```")[1].split("```")[0]
    
    result = json.loads(response_text.strip())
    
    # Calcular mÃ©tricas
    tokens_in = len(review_prompt.split()) * 1.3
    tokens_out = len(response_text.split()) * 1.3
    total_tokens = int(tokens_in + tokens_out)
    cost = estimate_cost(model_name, int(tokens_in), int(tokens_out))
    
    # Log da validaÃ§Ã£o
    is_valid = result.get("is_approved", False) and result.get("confidence_score", 0.0) >= min_confidence
    log_validation(
        node_name,
        is_valid,
        f"Confidence: {result.get('confidence_score', 0.0):.0%}"
    )
    
    return result, total_tokens, cost


def check_critical_issues(issues: list) -> bool:
    """
    Verifica se hÃ¡ issues crÃ­ticos na lista
    
    Args:
        issues: Lista de issues (pode ser strings ou dicts)
        
    Returns:
        True se hÃ¡ issues crÃ­ticos
    """
    for issue in issues:
        if isinstance(issue, dict):
            severity = issue.get("severity", "").lower()
            if severity == "critical":
                return True
        elif isinstance(issue, str) and "critical" in issue.lower():
            return True
    
    return False


def format_review_summary(review: Dict[str, Any]) -> str:
    """
    Formata um resumo legÃ­vel da revisÃ£o
    
    Args:
        review: Resultado da revisÃ£o
        
    Returns:
        String formatada com resumo
    """
    lines = []
    
    # Status
    is_approved = review.get("is_approved", False)
    confidence = review.get("confidence_score", 0.0)
    
    lines.append(f"{'âœ… APROVADO' if is_approved else 'âŒ NÃƒO APROVADO'}")
    lines.append(f"ConfianÃ§a: {confidence:.0%}")
    lines.append("")
    
    # Issues
    issues = review.get("issues_found", [])
    if issues:
        lines.append("âš ï¸ Issues Encontrados:")
        for issue in issues[:5]:  # Primeiros 5
            if isinstance(issue, dict):
                severity = issue.get("severity", "?")
                desc = issue.get("issue", str(issue))
                lines.append(f"  [{severity.upper()}] {desc}")
            else:
                lines.append(f"  â€¢ {issue}")
        if len(issues) > 5:
            lines.append(f"  ... e mais {len(issues) - 5} issue(s)")
        lines.append("")
    
    # SugestÃµes
    suggestions = review.get("suggestions", [])
    if suggestions:
        lines.append("ğŸ’¡ SugestÃµes:")
        for sug in suggestions[:3]:  # Primeiras 3
            if isinstance(sug, dict):
                desc = sug.get("suggestion", str(sug))
                lines.append(f"  â€¢ {desc}")
            else:
                lines.append(f"  â€¢ {sug}")
        if len(suggestions) > 3:
            lines.append(f"  ... e mais {len(suggestions) - 3} sugestÃ£o(Ãµes)")
        lines.append("")
    
    # Pontos fortes
    strengths = review.get("strengths", [])
    if strengths:
        lines.append("âœ¨ Pontos Fortes:")
        for strength in strengths[:3]:
            lines.append(f"  â€¢ {strength}")
        if len(strengths) > 3:
            lines.append(f"  ... e mais {len(strengths) - 3}")
    
    return "\n".join(lines)


def calculate_overall_quality_score(review: Dict[str, Any]) -> float:
    """
    Calcula um score geral de qualidade baseado na revisÃ£o
    
    Args:
        review: Resultado da revisÃ£o
        
    Returns:
        Score de 0.0 a 1.0
    """
    # ComeÃ§ar com confidence score
    score = review.get("confidence_score", 0.5)
    
    # Penalizar por issues
    issues = review.get("issues_found", [])
    critical_issues = sum(1 for i in issues if isinstance(i, dict) and i.get("severity") == "critical")
    high_issues = sum(1 for i in issues if isinstance(i, dict) and i.get("severity") == "high")
    
    score -= (critical_issues * 0.3)
    score -= (high_issues * 0.15)
    score -= (len(issues) * 0.05)
    
    # Bonificar por strengths
    strengths = review.get("strengths", [])
    score += (len(strengths) * 0.02)
    
    # Code quality scores (se existir)
    if "code_quality_score" in review:
        cqs = review["code_quality_score"]
        if isinstance(cqs, dict) and "overall" in cqs:
            code_score = cqs["overall"] / 10.0
            score = (score + code_score) / 2  # MÃ©dia
    
    # Limitar entre 0 e 1
    return max(0.0, min(1.0, score))


def should_retry_with_feedback(
    review: Dict[str, Any],
    max_retries: int,
    current_retry: int
) -> tuple[bool, Optional[str]]:
    """
    Determina se deve fazer retry com feedback
    
    Args:
        review: Resultado da revisÃ£o
        max_retries: MÃ¡ximo de retries permitidos
        current_retry: Retry atual
        
    Returns:
        Tupla (should_retry, feedback_message)
    """
    if current_retry >= max_retries:
        return False, None
    
    if review.get("is_approved", False):
        return False, None
    
    # Construir feedback
    issues = review.get("issues_found", [])
    suggestions = review.get("suggestions", [])
    
    feedback_parts = []
    
    if issues:
        feedback_parts.append("Issues encontrados que precisam ser corrigidos:")
        for issue in issues[:5]:
            if isinstance(issue, dict):
                feedback_parts.append(f"- {issue.get('issue', str(issue))}")
            else:
                feedback_parts.append(f"- {issue}")
    
    if suggestions:
        feedback_parts.append("\nSugestÃµes de melhoria:")
        for sug in suggestions[:5]:
            if isinstance(sug, dict):
                feedback_parts.append(f"- {sug.get('suggestion', str(sug))}")
            else:
                feedback_parts.append(f"- {sug}")
    
    feedback = "\n".join(feedback_parts)
    
    return True, feedback